#!/usr/bin/env python3
import subprocess
import sys

def check_onnxruntime_gpu():
    try:
        import onnxruntime as ort
        providers = ort.get_available_providers()
        gpu_support = 'CUDAExecutionProvider' in providers or 'ROCMExecutionProvider' in providers
        print(f"ONNX Runtime GPU: {'✓' if gpu_support else '✗'}")
        return gpu_support
    except ImportError:
        print("ONNX Runtime: Not installed")
        return False

def check_mxnet_cuda():
    try:
        import mxnet as mx
        gpu_support = mx.context.num_gpus() > 0
        print(f"MXNet CUDA: {'✓' if gpu_support else '✗'}")
        return gpu_support
    except ImportError:
        print("MXNet: Not installed")
        return False
    except Exception:
        print("MXNet CUDA: ✗")
        return False

def check_nvidia_smi():
    try:
        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], 
                              capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("nvidia-smi: ✓")
            for line in result.stdout.strip().split('\n'):
                if line.strip():
                    print(f"  GPU: {line.strip()}")
            return True
        else:
            print("nvidia-smi: ✗")
            return False
    except (subprocess.TimeoutExpired, FileNotFoundError):
        print("nvidia-smi: ✗ (not found)")
        return False

if __name__ == "__main__":
    print("GPU Support Check")
    print("-" * 20)
    
    onnx_ok = check_onnxruntime_gpu()
    mxnet_ok = check_mxnet_cuda()
    nvidia_ok = check_nvidia_smi()
    
    print(f"\nOverall GPU Ready: {'✓' if any([onnx_ok, mxnet_ok]) and nvidia_ok else '✗'}")

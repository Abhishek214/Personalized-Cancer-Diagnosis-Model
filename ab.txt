# Fix for Zero Output Issue in ONNX Conversion
# File: convert_onnx_zero_fix.py

import torch
import torch.nn as nn
import yaml
import argparse
import os
import numpy as np
import warnings
from backbone import EfficientDetBackbone
from efficientdet.utils import BBoxTransform, ClipBoxes
import torchvision

# Suppress warnings
warnings.filterwarnings("ignore")

def replace_batched_nms():
    """Replace batched_nms with ONNX-compatible version"""
    def onnx_batched_nms(boxes, scores, idxs, iou_threshold):
        if boxes.numel() == 0:
            return torch.empty((0,), dtype=torch.int64, device=boxes.device)
        
        max_coordinate = boxes.max()
        offsets = idxs.to(boxes) * (max_coordinate + torch.tensor(1.0))
        boxes_for_nms = boxes + offsets[:, None]
        keep = torchvision.ops.nms(boxes_for_nms, scores, iou_threshold)
        return keep
    
    torchvision.ops.boxes.batched_nms = onnx_batched_nms
    print("✓ Replaced batched_nms for ONNX compatibility")

def fix_swish_for_your_model(model):
    """Fix swish activations specifically for your model structure"""
    print("=== Fixing Swish Activations ===")
    
    try:
        if hasattr(model, 'backbone_net') and hasattr(model.backbone_net, 'model'):
            if hasattr(model.backbone_net.model, 'set_swish'):
                model.backbone_net.model.set_swish(memory_efficient=False)
                print("✓ Fixed backbone EfficientNet swish (set_swish method)")
        
        # Replace MemoryEfficientSwish with regular Swish
        swish_replaced = 0
        for name, module in model.named_modules():
            if '_swish' in name and 'MemoryEfficientSwish' in str(type(module)):
                parent_name = '.'.join(name.split('.')[:-1])
                if parent_name:
                    parent_module = model
                    for part in parent_name.split('.'):
                        parent_module = getattr(parent_module, part)
                    
                    from efficientnet.utils import Swish
                    setattr(parent_module, '_swish', Swish())
                    swish_replaced += 1
                    print(f"✓ Replaced MemoryEfficientSwish at {name}")
        
        print(f"✓ Replaced {swish_replaced} MemoryEfficientSwish modules")
        return True
        
    except Exception as e:
        print(f"❌ Swish fixing failed: {e}")
        return False

def diagnose_zero_outputs(model, dummy_input):
    """Diagnose why the model is producing zero outputs"""
    print("\n=== Diagnosing Zero Output Issue ===")
    
    model.eval()
    
    with torch.no_grad():
        # Test raw backbone outputs
        features, regression, classification, anchors = model(dummy_input)
        
        print(f"Raw backbone outputs:")
        print(f"  Features: {len(features)} feature maps")
        print(f"  Regression: {regression.shape}, range: [{regression.min():.4f}, {regression.max():.4f}]")
        print(f"  Classification: {classification.shape}, range: [{classification.min():.4f}, {classification.max():.4f}]")
        print(f"  Anchors: {anchors.shape}, range: [{anchors.min():.4f}, {anchors.max():.4f}]")
        
        # Check for actual content
        reg_nonzero = torch.count_nonzero(regression).item()
        cls_nonzero = torch.count_nonzero(classification).item()
        anchor_nonzero = torch.count_nonzero(anchors).item()
        
        print(f"  Non-zero elements: regression={reg_nonzero}, classification={cls_nonzero}, anchors={anchor_nonzero}")
        
        if reg_nonzero == 0 or cls_nonzero == 0:
            print("❌ Raw model outputs are zero - check model weights!")
            return False
        
        # Test classification scores after sigmoid
        classification_scores = torch.sigmoid(classification) if not torch.all((classification >= 0) & (classification <= 1)) else classification
        max_scores = torch.max(classification_scores, dim=2)[0]
        
        print(f"  Classification scores range: [{classification_scores.min():.4f}, {classification_scores.max():.4f}]")
        print(f"  Max scores per anchor: [{max_scores.min():.4f}, {max_scores.max():.4f}]")
        
        # Test different thresholds
        for thresh in [0.001, 0.01, 0.05, 0.1, 0.5]:
            count = torch.sum(max_scores > thresh).item()
            print(f"  Detections above {thresh}: {count}")
        
        return True

class DebugONNXWrapper(nn.Module):
    """ONNX wrapper with debugging for zero output issue"""
    
    def __init__(self, backbone, score_threshold=0.001, nms_threshold=0.5, max_detections=100):  # Lower threshold
        super().__init__()
        self.backbone = backbone
        self.score_threshold = score_threshold  # Start with very low threshold
        self.nms_threshold = nms_threshold
        self.max_detections = max_detections
        
        self.regressBoxes = BBoxTransform()
        self.clipBoxes = ClipBoxes()
    
    def forward(self, x):
        # Get backbone outputs
        features, regression, classification, anchors = self.backbone(x)
        
        # Apply postprocessing
        transformed_anchors = self.regressBoxes(anchors, regression)
        transformed_anchors = self.clipBoxes(transformed_anchors, x)
        
        # Check if classification already has sigmoid applied
        if torch.all((classification >= 0) & (classification <= 1)):
            classification_scores = classification
        else:
            classification_scores = torch.sigmoid(classification)
        
        # Get scores and classes
        scores = torch.max(classification_scores, dim=2, keepdim=True)[0]
        classes = torch.max(classification_scores, dim=2)[1]
        
        # Apply score threshold
        score_mask = scores > self.score_threshold
        score_mask = score_mask[:, :, 0]
        
        # Pre-allocate outputs
        batch_size = x.shape[0]
        final_boxes = torch.zeros((batch_size, self.max_detections, 4), device=x.device)
        final_scores = torch.zeros((batch_size, self.max_detections), device=x.device)
        final_classes = torch.zeros((batch_size, self.max_detections), device=x.device, dtype=torch.long)
        
        # Process each image in batch
        for i in range(batch_size):
            valid_count = torch.sum(score_mask[i]).item()
            
            if valid_count > 0:
                valid_boxes = transformed_anchors[i, score_mask[i], :]
                valid_scores = scores[i, score_mask[i], 0]
                valid_classes = classes[i, score_mask[i]]
                
                if len(valid_boxes) > 0:
                    # Apply NMS
                    keep = torchvision.ops.batched_nms(
                        valid_boxes, valid_scores, valid_classes, self.nms_threshold
                    )
                    
                    # Limit detections
                    keep = keep[:self.max_detections]
                    num_keep = len(keep)
                    
                    if num_keep > 0:
                        final_boxes[i, :num_keep] = valid_boxes[keep]
                        final_scores[i, :num_keep] = valid_scores[keep]
                        final_classes[i, :num_keep] = valid_classes[keep]
        
        return final_boxes, final_scores, final_classes

class Params:
    def __init__(self, project_file):
        self.params = yaml.safe_load(open(project_file).read())
    def __getattr__(self, item):
        return self.params.get(item, None)

def convert_with_zero_fix(project_file, weights_path, output_path, compound_coef=2, 
                         score_threshold=0.001, nms_threshold=0.5, max_detections=100):  # Very low threshold
    
    print("=== Converting with Zero Output Fix ===")
    
    replace_batched_nms()
    
    device = torch.device('cpu')
    params = Params(project_file)
    
    input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536, 1536]
    input_size = input_sizes[compound_coef]
    
    print(f"Creating model with {len(params.obj_list)} classes, compound_coef={compound_coef}")
    
    # Load model
    backbone = EfficientDetBackbone(
        num_classes=len(params.obj_list), 
        compound_coef=compound_coef, 
        onnx_export=True,
        ratios=eval(params.anchors_ratios), 
        scales=eval(params.anchors_scales)
    ).to(device)
    
    # Fix swish
    swish_fixed = fix_swish_for_your_model(backbone)
    
    # Load weights
    print(f"Loading weights from: {weights_path}")
    backbone.load_state_dict(torch.load(weights_path, map_location=device))
    backbone.eval()
    
    # Create dummy input
    dummy_input = torch.randn((1, 3, input_size, input_size), dtype=torch.float32)
    
    # Diagnose zero output issue
    if not diagnose_zero_outputs(backbone, dummy_input):
        print("❌ Model produces zero outputs, cannot proceed")
        return False
    
    # Create wrapper with very low threshold
    print(f"Creating ONNX wrapper with threshold {score_threshold}...")
    model = DebugONNXWrapper(backbone, score_threshold, nms_threshold, max_detections)
    model.eval()
    
    # Test wrapper
    print("Testing ONNX wrapper...")
    with torch.no_grad():
        wrapper_outputs = model(dummy_input)
        print(f"✓ Wrapper test successful, output shapes: {[t.shape for t in wrapper_outputs]}")
        
        # Check for content with detailed analysis
        for i, output in enumerate(wrapper_outputs):
            nonzero_count = torch.count_nonzero(output).item()
            output_range = f"[{output.min():.4f}, {output.max():.4f}]"
            print(f"  Output {i}: {nonzero_count} non-zero elements, range: {output_range}")
        
        total_nonzero = sum(torch.count_nonzero(t).item() for t in wrapper_outputs)
        print(f"✓ Total non-zero elements: {total_nonzero}")
        
        if total_nonzero == 0:
            print("⚠ Still getting zero outputs, trying even lower threshold...")
            # Try with extremely low threshold
            model_ultra_low = DebugONNXWrapper(backbone, 0.0001, nms_threshold, max_detections)
            wrapper_outputs = model_ultra_low(dummy_input)
            total_nonzero = sum(torch.count_nonzero(t).item() for t in wrapper_outputs)
            print(f"✓ With threshold 0.0001, total non-zero elements: {total_nonzero}")
            
            if total_nonzero > 0:
                model = model_ultra_low
                score_threshold = 0.0001
                print("✓ Using ultra-low threshold for export")
    
    # Export to ONNX
    try:
        print(f"Converting to ONNX (threshold={score_threshold})...")
        torch.onnx.export(
            model,
            dummy_input,
            output_path,
            verbose=False,
            input_names=['input'],
            output_names=['boxes', 'scores', 'classes'],
            opset_version=11,
            do_constant_folding=True,
            export_params=True,
            training=torch.onnx.TrainingMode.EVAL,
            dynamic_axes={
                'input': {0: 'batch_size'},
                'boxes': {0: 'batch_size'},
                'scores': {0: 'batch_size'},
                'classes': {0: 'batch_size'}
            }
        )
        
        # Check file size
        file_size = os.path.getsize(output_path) / (1024 * 1024)
        print(f"✓ ONNX export completed")
        print(f"✓ File size: {file_size:.1f} MB")
        
        if file_size < 1.0:
            print("❌ File size too small, export may have failed")
            return False
        
        # Validate
        validate_conversion(model, output_path, dummy_input)
        
        print(f"\n=== CONVERSION SUMMARY ===")
        print(f"✅ Successfully converted with score threshold: {score_threshold}")
        print(f"✅ ONNX file size: {file_size:.1f} MB")
        print(f"💡 You may need to adjust the score threshold during evaluation")
        
        return True
        
    except Exception as e:
        print(f"❌ ONNX export failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def validate_conversion(pytorch_model, onnx_path, test_input):
    """Validate the ONNX conversion"""
    try:
        import onnxruntime as ort
        print("Validating ONNX conversion...")
        
        session = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])
        
        with torch.no_grad():
            pytorch_outputs = pytorch_model(test_input)
        
        onnx_input = {session.get_inputs()[0].name: test_input.numpy()}
        onnx_outputs = session.run(None, onnx_input)
        
        print("Validation results:")
        all_good = True
        
        for i, (pt_out, onnx_out) in enumerate(zip(pytorch_outputs, onnx_outputs)):
            pt_np = pt_out.detach().numpy()
            diff = np.abs(pt_np - onnx_out).max()
            
            pt_nonzero = np.count_nonzero(pt_np)
            onnx_nonzero = np.count_nonzero(onnx_out)
            
            print(f"  Output {i}:")
            print(f"    Max diff: {diff:.2e}")
            print(f"    Non-zero: PyTorch={pt_nonzero}, ONNX={onnx_nonzero}")
            
            if pt_nonzero > 0 and onnx_nonzero > 0:
                print(f"    ✓ Both models produce outputs")
            elif pt_nonzero == 0 and onnx_nonzero == 0:
                print(f"    ⚠ Both models produce zero outputs (threshold too high?)")
            else:
                print(f"    ❌ Output mismatch")
                all_good = False
        
        return all_good
        
    except ImportError:
        print("⚠ onnxruntime not available for validation")
        return True
    except Exception as e:
        print(f"❌ Validation failed: {e}")
        return False

if __name__ == '__main__':
    parser = argparse.ArgumentParser('Convert with Zero Output Fix')
    parser.add_argument('-p', '--project', type=str, default='projects/abhil.yml')
    parser.add_argument('-c', '--compound_coef', type=int, default=2)
    parser.add_argument('-w', '--weights', type=str, required=True)
    parser.add_argument('-o', '--output', type=str, default='efficientdet_zero_fix.onnx')
    parser.add_argument('--score_threshold', type=float, default=0.001)  # Much lower default
    parser.add_argument('--nms_threshold', type=float, default=0.5)
    parser.add_argument('--max_detections', type=int, default=100)
    
    args = parser.parse_args()
    
    if not os.path.exists(args.weights):
        print(f"❌ Weights file not found: {args.weights}")
        exit(1)
    
    success = convert_with_zero_fix(
        args.project, args.weights, args.output, args.compound_coef,
        args.score_threshold, args.nms_threshold, args.max_detections
    )
    
    if success:
        print(f"✅ Conversion completed: {args.output}")
    else:
        print("❌ Conversion failed")

    model = get_model()
        self.net = model['session']
        
        # CRITICAL: Reduce image size for GCP
        original_shape = image.shape
        max_dim = max(image.shape[0], image.shape[1])
        
        # Force smaller image for inference
        if max_dim > 1024:  # Reduce from your current size
            import cv2
            scale = 1024 / max_dim
            new_height = int(image.shape[0] * scale)
            new_width = int(image.shape[1] * scale)
            
            self.logger.info(f"Resizing image from {original_shape} to ({new_height}, {new_width})")
            image = cv2.resize(image, (new_width, new_height))
        
        img_nd = mx.nd.array(image, ctx=mx.cpu())
        
        # Use smaller short size for transform
        x, img = self.net.transform_test(img_nd, short=512)  # Reduced from 1024
        
        # Inference with batch size 1
        with mx.autograd.predict_mode():  # Ensure prediction mode
            class_IDs, scores, bounding_boxes = self.net(x)
        
        # Scale bboxes back to original size if resized
        if max_dim > 1024:
            scale_back = max_dim / 1024
            bounding_boxes = bounding_boxes * scale_back

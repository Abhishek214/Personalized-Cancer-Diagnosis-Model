# Fixed ONNX Conversion Script with Proper NMS
# File: convert_onnx_fixed_v2.py

import torch
import torch.nn as nn
import yaml
import argparse
import os
import numpy as np
from collections import OrderedDict
from backbone import EfficientDetBackbone
from efficientdet.utils import BBoxTransform, ClipBoxes
import torchvision

# CRITICAL FIX 1: Replace batched_nms before any imports to ensure ONNX compatibility
def replace_batched_nms():
    """Replace torchvision's batched_nms with ONNX-compatible version"""
    try:
        from torchvision.ops.boxes import _batched_nms_coordinate_trick
        torchvision.ops.boxes.batched_nms = _batched_nms_coordinate_trick
        print("Successfully replaced batched_nms with ONNX-compatible version")
    except ImportError:
        print("Warning: Could not import _batched_nms_coordinate_trick, using fallback")
        # Fallback implementation
        def onnx_batched_nms(boxes, scores, idxs, iou_threshold):
            if boxes.numel() == 0:
                return torch.empty((0,), dtype=torch.int64, device=boxes.device)
            
            max_coordinate = boxes.max()
            offsets = idxs.to(boxes) * (max_coordinate + 1)
            boxes_for_nms = boxes + offsets[:, None]
            keep = torchvision.ops.nms(boxes_for_nms, scores, iou_threshold)
            return keep
        
        torchvision.ops.boxes.batched_nms = onnx_batched_nms

# Apply the fix before any model imports
replace_batched_nms()

class EfficientDetWithProperPostProcess(nn.Module):
    """EfficientDet with proper NMS postprocessing for ONNX export"""
    
    def __init__(self, backbone, score_threshold=0.05, nms_threshold=0.5, max_detections=100):
        super().__init__()
        self.backbone = backbone
        self.score_threshold = score_threshold
        self.nms_threshold = nms_threshold
        self.max_detections = max_detections
        self.regressBoxes = BBoxTransform()
        self.clipBoxes = ClipBoxes()
    
    def forward(self, x):
        # Get model outputs - SAME as original PyTorch model
        features, regression, classification, anchors = self.backbone(x)
        
        # Transform boxes - SAME as original
        transformed_anchors = self.regressBoxes(anchors, regression)
        transformed_anchors = self.clipBoxes(transformed_anchors, x)
        
        # FIX 2: Don't apply sigmoid again - classification already has sigmoid applied
        # Original code incorrectly applied sigmoid twice
        classification_scores = classification  # Already contains sigmoid output
        
        # FIX 3: Proper score and class extraction matching original postprocess
        scores = torch.max(classification_scores, dim=2, keepdim=True)[0]
        classes = torch.max(classification_scores, dim=2)[1]
        
        # Apply score threshold
        score_mask = (scores > self.score_threshold)[:, :, 0]
        
        # FIX 4: Handle batch processing properly (original processes per image)
        batch_size = x.shape[0]
        final_boxes_list = []
        final_scores_list = []
        final_classes_list = []
        
        for i in range(batch_size):
            if score_mask[i].sum() == 0:
                # No detections above threshold
                final_boxes_list.append(torch.empty((0, 4), device=x.device))
                final_scores_list.append(torch.empty((0,), device=x.device))
                final_classes_list.append(torch.empty((0,), device=x.device, dtype=torch.long))
                continue
            
            # Get valid detections for this image
            valid_boxes = transformed_anchors[i, score_mask[i], :]
            valid_scores = scores[i, score_mask[i], 0]
            valid_classes = classes[i, score_mask[i]]
            
            # FIX 5: Apply proper NMS instead of top-k selection
            # This matches the original postprocess function behavior
            keep_indices = torchvision.ops.batched_nms(
                valid_boxes, 
                valid_scores, 
                valid_classes, 
                self.nms_threshold
            )
            
            # Limit to max detections
            if len(keep_indices) > self.max_detections:
                keep_indices = keep_indices[:self.max_detections]
            
            final_boxes_list.append(valid_boxes[keep_indices])
            final_scores_list.append(valid_scores[keep_indices])
            final_classes_list.append(valid_classes[keep_indices])
        
        # FIX 6: Return tensors in format expected by evaluation script
        # Pad to max_detections for consistent ONNX output shape
        max_dets = max(len(boxes) for boxes in final_boxes_list) if final_boxes_list else 1
        max_dets = min(max_dets, self.max_detections)
        
        batch_boxes = torch.zeros((batch_size, max_dets, 4), device=x.device)
        batch_scores = torch.zeros((batch_size, max_dets), device=x.device)
        batch_classes = torch.zeros((batch_size, max_dets), device=x.device, dtype=torch.long)
        
        for i, (boxes, scores, classes) in enumerate(zip(final_boxes_list, final_scores_list, final_classes_list)):
            if len(boxes) > 0:
                num_dets = min(len(boxes), max_dets)
                batch_boxes[i, :num_dets] = boxes[:num_dets]
                batch_scores[i, :num_dets] = scores[:num_dets]
                batch_classes[i, :num_dets] = classes[:num_dets]
        
        return batch_boxes, batch_scores, batch_classes


class Params:
    def __init__(self, project_file):
        self.params = yaml.safe_load(open(project_file).read())

    def __getattr__(self, item):
        return self.params.get(item, None)

def convert_to_onnx(project_file, weights_path, output_path, compound_coef=2, 
                   score_threshold=0.05, nms_threshold=0.5, max_detections=100):
    device = torch.device('cpu')
    params = Params(project_file)
    
    # Input sizes for different compound coefficients
    input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536, 1536]
    input_size = input_sizes[compound_coef]
    
    print(f"Loading model with {len(params.obj_list)} classes, compound_coef={compound_coef}")
    
    # Create backbone model - SAME as original
    backbone = EfficientDetBackbone(
        num_classes=len(params.obj_list), 
        compound_coef=compound_coef, 
        onnx_export=True,  # Important for ONNX compatibility
        ratios=eval(params.anchors_ratios), 
        scales=eval(params.anchors_scales)
    ).to(device)
    
    # FIX 7: Ensure proper swish activation for ONNX export
    backbone.backbone_net.model.set_swish(memory_efficient=False)
    
    # Load weights - SAME as original
    print(f"Loading weights from: {weights_path}")
    backbone.load_state_dict(torch.load(weights_path, map_location=device))
    
    # Create model with proper postprocessing
    model = EfficientDetWithProperPostProcess(
        backbone, score_threshold, nms_threshold, max_detections
    )
    model.eval()
    
    # Create dummy input - SAME as original
    dummy_input = torch.randn((1, 3, input_size, input_size), dtype=torch.float32).to(device)
    
    print(f"Converting to ONNX with proper NMS (score_thresh={score_threshold}, nms_thresh={nms_threshold})")
    
    # FIX 8: Use model tracing for better ONNX export reliability
    with torch.no_grad():
        traced_model = torch.jit.trace(model, dummy_input)
    
    # Export to ONNX with essential settings preserved
    torch.onnx.export(
        traced_model,  # Use traced model instead of direct model
        dummy_input, 
        output_path,
        verbose=True,
        input_names=['input'],
        output_names=['boxes', 'scores', 'classes'],
        opset_version=11,  # Stable opset with good NMS support
        do_constant_folding=True,
        dynamic_axes={
            'input': {0: 'batch_size'},
            'boxes': {0: 'batch_size', 1: 'num_detections'},
            'scores': {0: 'batch_size', 1: 'num_detections'},
            'classes': {0: 'batch_size', 1: 'num_detections'}
        }
    )
    
    print(f"ONNX model with proper NMS saved to: {output_path}")
    
    # FIX 9: Validate the conversion
    print("Validating ONNX model...")
    validate_onnx_conversion(traced_model, output_path, dummy_input)

def validate_onnx_conversion(pytorch_model, onnx_path, test_input):
    """Validate that ONNX model produces similar outputs to PyTorch model"""
    import onnxruntime as ort
    
    # Get PyTorch output
    with torch.no_grad():
        pytorch_output = pytorch_model(test_input)
    
    # Get ONNX output
    session = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])
    onnx_input = {session.get_inputs()[0].name: test_input.numpy()}
    onnx_output = session.run(None, onnx_input)
    
    # Compare outputs
    print("Validation Results:")
    for i, (pt_out, onnx_out) in enumerate(zip(pytorch_output, onnx_output)):
        pt_tensor = pt_out.numpy()
        diff = np.abs(pt_tensor - onnx_out).max()
        print(f"  Output {i}: Max difference = {diff:.2e}")
        if diff > 1e-4:
            print(f"    WARNING: Large difference detected!")
        else:
            print(f"    âœ“ Good match")

if __name__ == '__main__':
    parser = argparse.ArgumentParser('Convert EfficientDet to ONNX with proper NMS')
    parser.add_argument('-p', '--project', type=str, default='projects/abhil.yml', help='Project file')
    parser.add_argument('-c', '--compound_coef', type=int, default=2, help='EfficientDet compound coefficient')
    parser.add_argument('-w', '--weights', type=str, required=True, help='Path to weights file')
    parser.add_argument('-o', '--output', type=str, default='efficientdet_proper_nms.onnx', help='Output ONNX file path')
    parser.add_argument('--score_threshold', type=float, default=0.05, help='Score threshold for filtering detections')
    parser.add_argument('--nms_threshold', type=float, default=0.5, help='NMS threshold')
    parser.add_argument('--max_detections', type=int, default=100, help='Maximum number of detections to output')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.weights):
        raise FileNotFoundError(f"Weights file not found: {args.weights}")
    
    convert_to_onnx(args.project, args.weights, args.output, args.compound_coef, 
                   args.score_threshold, args.nms_threshold, args.max_detections)
